{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()\n",
    "np.set_printoptions(5,)\n",
    "assert int(tf.__version__[0]) == 2, \"tensorflow 2.0 should be installed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "ROOT_URL = \"https://craftsangjae.s3.ap-northeast-2.amazonaws.com/data/\"\n",
    "\n",
    "play_path = get_file(\"lastfm_play.csv\",\n",
    "                     ROOT_URL+\"lastfm_play.csv\")\n",
    "artist_path = get_file(\"lastfm_artist.csv\",\n",
    "                       ROOT_URL+\"lastfm_artist.csv\")\n",
    "user_path = get_file(\"lastfm_user.csv\",\n",
    "                     ROOT_URL+\"lastfm_user.csv\")\n",
    "\n",
    "play_df = pd.read_csv(play_path)\n",
    "artist_df = pd.read_csv(artist_path)\n",
    "user_df = pd.read_csv(user_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Collaborative Filtering\n",
    "---\n",
    "\n",
    "![](https://imgur.com/2XCYGE8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def neural_collaborative_filtering(num_user,num_item, num_factor):\n",
    "    user_id = Input(shape=(), name='user')\n",
    "    item_id = Input(shape=(), name='item')\n",
    "    \n",
    "    user_embedding = Embedding(num_user, num_factor)(user_id)\n",
    "    item_embedding = Embedding(num_item, num_factor)(item_id)\n",
    "    \n",
    "    concat_embedding = Concatenate()([user_embedding, item_embedding])\n",
    "    \n",
    "    hidden1 = Dense(num_factor,    activation='relu')(concat_embedding)\n",
    "    hidden2 = Dense(num_factor//2, activation='relu')(hidden1)\n",
    "    hidden3 = Dense(num_factor//4, activation='relu')(hidden2)\n",
    "    probs = Dense(1, activation='sigmoid')(hidden3)\n",
    "    \n",
    "    model = Model([user_id, item_id],  probs, name='NCF')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = play_df.user_id.max() + 1\n",
    "num_item = play_df.artist_id.max() + 1\n",
    "num_factor = 32\n",
    "\n",
    "model = neural_collaborative_filtering(num_user, num_item, num_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "model.compile(Adam(1e-3), \n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Data Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_dataset(df, neg_ratio=3., batch_size=128):\n",
    "    pos_df = df[['user_id','artist_id']].copy()\n",
    "    neg_df = df[['user_id','artist_id']].sample(\n",
    "        frac=neg_ratio, replace=True).copy()\n",
    "    neg_df.artist_id = neg_df.artist_id.sample(frac=1.).values\n",
    "    \n",
    "    pos_df['label'] = 1.\n",
    "    neg_df['label'] = 0.\n",
    "    merge_df = pd.concat([pos_df,neg_df]).sample(frac=1.)\n",
    "    \n",
    "    X = {\n",
    "        \"user\": merge_df['user_id'].values,\n",
    "        \"item\": merge_df['artist_id'].values\n",
    "    }\n",
    "    Y = merge_df.label.values\n",
    "    \n",
    "    dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X,Y))\n",
    "    .batch(batch_size))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10\n",
    "batch_size = 1024 * 16\n",
    "for i in range(num_epoch):\n",
    "    print(f\"{i+1}th epoch :\")\n",
    "    dataset = bootstrap_dataset(play_df, num_epoch, batch_size)\n",
    "    model.fit(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
