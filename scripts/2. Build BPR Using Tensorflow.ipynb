{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Matrix Factorization이란, 주어진 고객과 제품 간의 상호작용 행렬로부터 고객의 취향 정보 행렬과 제품의 특성 정보 행렬을 도출하는 과정을 의미합니다. \n",
    "\n",
    "<img src=\"https://i.imgur.com/QnC5xQx.png\" width=\"800\" >\n",
    "<br>\n",
    "위의 그림을 다르게 묘사하면 아래와 같습니다.\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/zvx2JNs.png\" width=\"400\" >\n",
    "\n",
    "유저의 취향 행렬과 제품의 특성 행렬을 얻게 되면, 우리는 크게 3가지의 작업을 할 수 있게 됩니다.<br>\n",
    "- Rating Prediction : 유저가 경험해보지 않은 아이템에 대한 선호도 예측하기\n",
    "- User Clustering : 유사한 취향을 가진 유저 묶기 \n",
    "- Item Clustering : 유사한 특성을 가진 아이템 묶기\n",
    "\n",
    "Matrix Factorization의 핵심은 어떻게 User Matrix와 Item Matrix을 구할 수 있는가입니다. \n",
    "\n",
    "\n",
    "고객행동 데이터 중 암묵 데이터를 활용할 때 사용하는 Matrix Factorization 알고리즘 중 하나인 베이지안 개인화 랭킹 알고리즘(BPR, Bayesian Personalized Ranking)을 Tensorflow을 통해 구현해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 모듈 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()\n",
    "np.set_printoptions(5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "ROOT_URL = \"https://craftsangjae.s3.ap-northeast-2.amazonaws.com/data/\"\n",
    "\n",
    "# 데이터 가져오기\n",
    "play_path = get_file(\"lastfm_play.csv\",\n",
    "                     ROOT_URL+\"lastfm_play.csv\")\n",
    "artist_path = get_file(\"lastfm_artist.csv\",\n",
    "                       ROOT_URL+\"lastfm_artist.csv\")\n",
    "user_path = get_file(\"lastfm_user.csv\",\n",
    "                     ROOT_URL+\"lastfm_user.csv\")\n",
    "\n",
    "play_df = pd.read_csv(play_path)\n",
    "artist_df = pd.read_csv(artist_path)\n",
    "user_df = pd.read_csv(user_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Personalized Ranking 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 구성하기\n",
    "\n",
    "Bayesian Personalized Ranking의 핵심 아이디어는 바로 \n",
    "\n",
    "> 고객이 구매/청취한 제품은 고객이 구매/청취하지 않은 제품보다 선호도가 높다\n",
    "\n",
    "입니다. Bayesain Personalized Ranking에서는 고객과 고객이 청취한 아티스트, 그리고 고객이 청취하지 않은 아티스트 총 3 개의 입력이 들어가게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "user_id = Input(shape=(), name='user')  # name : user\n",
    "pos_item_id = Input(shape=(), name='pos_item') # name : positive_item \n",
    "neg_item_id = Input(shape=(), name='neg_item') # name : negative_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 레이어 구성하기\n",
    "\n",
    "Bayesian Personalized Ranking에서 해야하는 것은 상호작용 정보를 통해 유저와 아이템에 대한 적절한 임베딩 값을 추론하는 것입니다. 임베딩 레이어를 아래처럼 생성합니다. 이 때 Item Embedding의 경우, 각 아이템 별 편향 정보(Bias)를 추가하기 위해 Num Factor에 1을 더했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "\n",
    "num_user = play_df.user_id.max() + 1\n",
    "num_item = play_df.artist_id.max() + 1\n",
    "num_factor = 32\n",
    "\n",
    "# 초기화 함수 : Uniform 분포\n",
    "init_range = 1 / (2*num_factor)\n",
    "initializer = RandomUniform(minval=-init_range, maxval=init_range)\n",
    "\n",
    "# Embedding Layer 선언하기\n",
    "user_embedding_layer = Embedding(num_user, num_factor, \n",
    "                                 embeddings_initializer=initializer,\n",
    "                                 name='user_embedding')\n",
    "item_embedding_layer = Embedding(num_item, num_factor, \n",
    "                                 embeddings_initializer=initializer,\n",
    "                                 name='item_embedding')\n",
    "item_bias_layer = Embedding(num_item, 1, \n",
    "                            embeddings_initializer='zeros',\n",
    "                            name='item_bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Embedding, User Embedding 구하기\n",
    "\n",
    "Tensorflow Keras에서 Item Embedding의 값과 User Embedding의 값을 가져오는 것은 매우 간단합니다. 우리는 층의 연결을 통해 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Embedding 구하기\n",
    "\n",
    "이 때 주의해야 하는 것은 positive item과 negative item은 같은 임베딩 레이어에서 가져와야 합니다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_item_embedding = item_embedding_layer(pos_item_id)\n",
    "neg_item_embedding = item_embedding_layer(neg_item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Embedding 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "user_embedding = user_embedding_layer(user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Bias 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_item_bias = item_bias_layer(pos_item_id)\n",
    "neg_item_bias = item_bias_layer(neg_item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 계산하기\n",
    "\n",
    "우리는 고객이 본 아이템에 대한 Score와 고객이 보지 않은 아이템에 대한 Score의 차이가 극대화되도록 학습하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dot\n",
    "from tensorflow.keras.layers import Subtract\n",
    "\n",
    "pos_score = (\n",
    "    Dot(axes=(1,1))([user_embedding, pos_item_embedding]) + pos_item_bias)\n",
    "neg_score = (\n",
    "    Dot(axes=(1,1))([user_embedding, neg_item_embedding]) + neg_item_bias)\n",
    "\n",
    "score = Subtract()([pos_score, neg_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization 적용하기\n",
    "\n",
    "\n",
    "Matrix Factoriation은 쉽게 과적합이 발생합니다. 특히 `item_embedding`의 bias factor는 쉽게 과적합될 수 있습니다. 이를 줄이기 위해 regularization으로 `l2`를 두게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "l2_reg = 1e-2\n",
    "\n",
    "l2_pos_item = tf.reduce_sum(pos_item_embedding**2)\n",
    "l2_neg_item = tf.reduce_sum(neg_item_embedding**2)\n",
    "l2_user = tf.reduce_sum(user_embedding**2)\n",
    "\n",
    "weight_decay = l2_reg * (l2_pos_item+l2_neg_item+l2_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 구성하기\n",
    "\n",
    "입력값은 크게 세가지 `user_id`, `pos_item_id`,`neg_item_id`으로 나뉘어집니다. 그리고 출력값은 보지 않은 아이템에 대한 선호도보다 본 아이템에 대한 선호도가 높을 확률(`probs`)이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bpr_model(num_user, num_item, num_factor, l2_reg=1e-2):\n",
    "    user_id = Input(shape=(), name='user')\n",
    "    pos_item_id = Input(shape=(), name='pos_item')\n",
    "    neg_item_id = Input(shape=(), name='neg_item')\n",
    "    \n",
    "    initializer = RandomUniform(minval=-1/num_factor, maxval=1/num_factor)\n",
    "    \n",
    "    user_embedding_layer = Embedding(num_user, num_factor, \n",
    "                                     embeddings_initializer=initializer,\n",
    "                                     name='user_embedding')\n",
    "    item_embedding_layer = Embedding(num_item, num_factor, \n",
    "                                     embeddings_initializer=initializer,\n",
    "                                     name='item_embedding')\n",
    "    item_bias_layer = Embedding(num_item, 1, \n",
    "                                embeddings_initializer='zeros',\n",
    "                                name='item_bias')\n",
    "    \n",
    "    pos_item_embedding = item_embedding_layer(pos_item_id)\n",
    "    neg_item_embedding = item_embedding_layer(neg_item_id)\n",
    "    \n",
    "    user_embedding = user_embedding_layer(user_id)\n",
    "    \n",
    "    pos_item_bias = item_bias_layer(pos_item_id)\n",
    "    neg_item_bias = item_bias_layer(neg_item_id)\n",
    "        \n",
    "    pos_score = (\n",
    "        Dot(axes=(1,1))([user_embedding, pos_item_embedding]) + pos_item_bias)\n",
    "    neg_score = (\n",
    "        Dot(axes=(1,1))([user_embedding, neg_item_embedding]) + neg_item_bias)\n",
    "\n",
    "    score = Subtract()([pos_score, neg_score])\n",
    "    \n",
    "    model = Model([user_id, pos_item_id, neg_item_id], score)\n",
    "    \n",
    "    l2_pos_item = tf.reduce_sum(pos_item_embedding**2)\n",
    "    l2_neg_item = tf.reduce_sum(neg_item_embedding**2)\n",
    "    l2_user = tf.reduce_sum(user_embedding**2)\n",
    "\n",
    "    weight_decay = l2_reg * (l2_pos_item+l2_neg_item+l2_user)\n",
    "\n",
    "    model.add_loss(weight_decay)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = create_bpr_model(num_user, num_item, 32, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 컴파일하기\n",
    "\n",
    "옵티마이저로는 `Adagrad`를 이용합니다. Sparse한 input을 다룰 때에 `Adagrad`는 SGD보다 훨씬 빠르게 수렴시킬 수 있습니다.\n",
    "\n",
    "그리고 Loss를 구할 때, aggregation 방식은 **평균** 대신 **합계**가 씁니다. 모든 input Feature에 대해 가중치를 공유하는 `Conv`,`Dense`,`RNN` 등과 달리, 각 input feature에 대해서 독립적으로 가중치를 적용하기 때문에 평균으로 할 경우 각 임베딩 weight에 대한 가중치가 배치 사이즈만큼 나누어주는 효과가 발생하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "def bpr_loss(y_true, y_pred):\n",
    "    return tf.reduce_sum(-tf.math.log(sigmoid(y_pred)))\n",
    "\n",
    "model.compile(Adagrad(1e-1), loss=bpr_loss,\n",
    "              metrics=[bpr_loss, BinaryAccuracy(threshold=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터 파이프라인 구성하기\n",
    "\n",
    "BPR의 손실함수인 Triplet Loss를 계산하기 위해서는 Dataset을 Bootstraping을 통해 샘플링해야합니다. 이 때 주의해야 할 것 중 하나는 바로 negative Case를 Sampling할 때에도 원래 item의 분포와 동일하게 sampling을 해주어야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "\n",
    "bootstrap = play_df.sample(frac=1., replace=True)\n",
    "user_ids = bootstrap.user_id.values\n",
    "pos_item_ids = bootstrap.artist_id.values\n",
    "neg_item_ids = play_df.artist_id.sample(frac=1., replace=True).values\n",
    "\n",
    "X = {\n",
    "    \"user\": user_ids,\n",
    "    \"pos_item\": pos_item_ids,\n",
    "    \"neg_item\": neg_item_ids\n",
    "}\n",
    "dummy_y = np.ones((len(bootstrap), 1))\n",
    "\n",
    "dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X,dummy_y))\n",
    "    .batch(batch_size)) # 배치 단위로 record 묶기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_dataset(df, batch_size=4096):\n",
    "    bootstrap = df.sample(frac=1., replace=True)\n",
    "    user_ids = bootstrap.user_id.values\n",
    "    pos_item_ids = bootstrap.artist_id.values\n",
    "    neg_item_ids = df.artist_id.sample(frac=1., replace=True).values\n",
    "\n",
    "    X = {\n",
    "        \"user\": user_ids,\n",
    "        \"pos_item\": pos_item_ids,\n",
    "        \"neg_item\": neg_item_ids\n",
    "    }\n",
    "    dummy_y = np.ones((len(bootstrap), 1))\n",
    "    \n",
    "    dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((X,dummy_y))\n",
    "        .batch(batch_size)) # 배치 단위로 record 묶기\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습하기\n",
    "\n",
    "epoch 10번에 걸쳐 모델을 학습시키도록 하겠습니다. 매 Epoch마다 새로운 학습 pair를 생성하도록 하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th epoch\n",
      "4225/4225 [==============================] - 81s 19ms/step - loss: 2271.9033 - bpr_loss: 2099.7532 - binary_accuracy: 0.7349\n",
      "2th epoch\n",
      "4225/4225 [==============================] - 70s 16ms/step - loss: 1569.7872 - bpr_loss: 1228.6342 - binary_accuracy: 0.8907\n",
      "3th epoch\n",
      "4225/4225 [==============================] - 68s 16ms/step - loss: 1437.0178 - bpr_loss: 1060.0135 - binary_accuracy: 0.9085\n",
      "4th epoch\n",
      "4225/4225 [==============================] - 68s 16ms/step - loss: 1378.5002 - bpr_loss: 980.3517 - binary_accuracy: 0.9170\n",
      "5th epoch\n",
      "4225/4225 [==============================] - 68s 16ms/step - loss: 1344.8147 - bpr_loss: 931.5139 - binary_accuracy: 0.9220\n",
      "6th epoch\n",
      "4225/4225 [==============================] - 69s 16ms/step - loss: 1322.5952 - bpr_loss: 897.7891 - binary_accuracy: 0.9255\n",
      "7th epoch\n",
      "4225/4225 [==============================] - 65s 15ms/step - loss: 1306.3130 - bpr_loss: 872.2475 - binary_accuracy: 0.9284\n",
      "8th epoch\n",
      "4225/4225 [==============================] - 82s 19ms/step - loss: 1294.6962 - bpr_loss: 853.0356 - binary_accuracy: 0.9303\n",
      "9th epoch\n",
      "4225/4225 [==============================] - 79s 19ms/step - loss: 1284.1813 - bpr_loss: 835.9705 - binary_accuracy: 0.9322\n",
      "10th epoch\n",
      "4225/4225 [==============================] - 82s 19ms/step - loss: 1276.6708 - bpr_loss: 822.9389 - binary_accuracy: 0.9336\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "batch_size = 4096\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    print(f\"{i+1}th epoch\")\n",
    "    dataset = bootstrap_dataset(play_df, batch_size)\n",
    "    model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 임베딩 행렬 가져오기\n",
    "학습된 임베딩 행렬은 `model.user_factors`와 `model.item_factors`에 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = model.get_layer('user_embedding').get_weights()[0]\n",
    "\n",
    "item_embeddings = model.get_layer('item_embedding').get_weights()[0]\n",
    "\n",
    "item_bias = model.get_layer('item_bias').get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좀 더 가독성을 높이기 위해서 각 임베딩 행 별로 아티스트의 이름과 유저의 id를 매칭시켜 데이터프레임(dataframe)을 구성하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16628],\n",
       "       [ 0.17658],\n",
       "       [-0.02754],\n",
       "       ...,\n",
       "       [ 0.10557],\n",
       "       [ 0.07174],\n",
       "       [ 0.16388]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>betty blowtorch</th>\n",
       "      <td>0.347647</td>\n",
       "      <td>0.345300</td>\n",
       "      <td>0.283413</td>\n",
       "      <td>0.124686</td>\n",
       "      <td>0.457707</td>\n",
       "      <td>-0.814453</td>\n",
       "      <td>-0.275293</td>\n",
       "      <td>-0.316983</td>\n",
       "      <td>0.060874</td>\n",
       "      <td>-0.383601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130088</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.192937</td>\n",
       "      <td>-0.425993</td>\n",
       "      <td>-0.030325</td>\n",
       "      <td>0.125157</td>\n",
       "      <td>-0.189928</td>\n",
       "      <td>0.053410</td>\n",
       "      <td>-0.054539</td>\n",
       "      <td>0.166278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die Ärzte</th>\n",
       "      <td>-0.609451</td>\n",
       "      <td>-0.122681</td>\n",
       "      <td>0.116881</td>\n",
       "      <td>-0.022823</td>\n",
       "      <td>0.063232</td>\n",
       "      <td>0.109007</td>\n",
       "      <td>0.188018</td>\n",
       "      <td>0.111158</td>\n",
       "      <td>-0.349701</td>\n",
       "      <td>0.200430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153900</td>\n",
       "      <td>-0.195210</td>\n",
       "      <td>-0.152610</td>\n",
       "      <td>-0.310218</td>\n",
       "      <td>-0.121051</td>\n",
       "      <td>-0.247437</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>0.138030</td>\n",
       "      <td>0.167068</td>\n",
       "      <td>0.176579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melissa etheridge</th>\n",
       "      <td>0.183831</td>\n",
       "      <td>0.231989</td>\n",
       "      <td>0.406555</td>\n",
       "      <td>0.037937</td>\n",
       "      <td>-0.058550</td>\n",
       "      <td>-0.229385</td>\n",
       "      <td>-0.528049</td>\n",
       "      <td>0.191282</td>\n",
       "      <td>0.161729</td>\n",
       "      <td>0.166509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135420</td>\n",
       "      <td>-0.035317</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>0.639455</td>\n",
       "      <td>-0.345175</td>\n",
       "      <td>-0.664175</td>\n",
       "      <td>-0.121457</td>\n",
       "      <td>0.261626</td>\n",
       "      <td>-0.027541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elvenking</th>\n",
       "      <td>-0.558999</td>\n",
       "      <td>-0.287427</td>\n",
       "      <td>0.143505</td>\n",
       "      <td>0.405830</td>\n",
       "      <td>0.470800</td>\n",
       "      <td>0.099769</td>\n",
       "      <td>0.181633</td>\n",
       "      <td>-0.412667</td>\n",
       "      <td>-0.172376</td>\n",
       "      <td>-0.581064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056614</td>\n",
       "      <td>-0.340192</td>\n",
       "      <td>0.151076</td>\n",
       "      <td>-0.496645</td>\n",
       "      <td>0.362071</td>\n",
       "      <td>-0.291823</td>\n",
       "      <td>-0.117428</td>\n",
       "      <td>-0.229639</td>\n",
       "      <td>0.362357</td>\n",
       "      <td>-0.488120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>juliette &amp; the licks</th>\n",
       "      <td>-0.127612</td>\n",
       "      <td>0.213415</td>\n",
       "      <td>0.042106</td>\n",
       "      <td>-0.131089</td>\n",
       "      <td>-0.251563</td>\n",
       "      <td>-0.844970</td>\n",
       "      <td>-0.409262</td>\n",
       "      <td>-0.352434</td>\n",
       "      <td>-0.104454</td>\n",
       "      <td>0.114784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250796</td>\n",
       "      <td>0.141587</td>\n",
       "      <td>-0.242373</td>\n",
       "      <td>-0.092049</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>0.240175</td>\n",
       "      <td>0.226212</td>\n",
       "      <td>0.686269</td>\n",
       "      <td>0.137652</td>\n",
       "      <td>0.663241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3         4   \\\n",
       "artist_name                                                              \n",
       "betty blowtorch       0.347647  0.345300  0.283413  0.124686  0.457707   \n",
       "die Ärzte            -0.609451 -0.122681  0.116881 -0.022823  0.063232   \n",
       "melissa etheridge     0.183831  0.231989  0.406555  0.037937 -0.058550   \n",
       "elvenking            -0.558999 -0.287427  0.143505  0.405830  0.470800   \n",
       "juliette & the licks -0.127612  0.213415  0.042106 -0.131089 -0.251563   \n",
       "\n",
       "                            5         6         7         8         9   ...  \\\n",
       "artist_name                                                             ...   \n",
       "betty blowtorch      -0.814453 -0.275293 -0.316983  0.060874 -0.383601  ...   \n",
       "die Ärzte             0.109007  0.188018  0.111158 -0.349701  0.200430  ...   \n",
       "melissa etheridge    -0.229385 -0.528049  0.191282  0.161729  0.166509  ...   \n",
       "elvenking             0.099769  0.181633 -0.412667 -0.172376 -0.581064  ...   \n",
       "juliette & the licks -0.844970 -0.409262 -0.352434 -0.104454  0.114784  ...   \n",
       "\n",
       "                            23        24        25        26        27  \\\n",
       "artist_name                                                              \n",
       "betty blowtorch       0.130088  0.014209  0.192937 -0.425993 -0.030325   \n",
       "die Ärzte            -0.153900 -0.195210 -0.152610 -0.310218 -0.121051   \n",
       "melissa etheridge    -0.135420 -0.035317 -0.147862  0.521583  0.639455   \n",
       "elvenking            -0.056614 -0.340192  0.151076 -0.496645  0.362071   \n",
       "juliette & the licks  0.250796  0.141587 -0.242373 -0.092049  0.015458   \n",
       "\n",
       "                            28        29        30        31        32  \n",
       "artist_name                                                             \n",
       "betty blowtorch       0.125157 -0.189928  0.053410 -0.054539  0.166278  \n",
       "die Ärzte            -0.247437 -0.001620  0.138030  0.167068  0.176579  \n",
       "melissa etheridge    -0.345175 -0.664175 -0.121457  0.261626 -0.027541  \n",
       "elvenking            -0.291823 -0.117428 -0.229639  0.362357 -0.488120  \n",
       "juliette & the licks  0.240175  0.226212  0.686269  0.137652  0.663241  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_df = pd.DataFrame(user_embeddings,\n",
    "                                 index=user_df.user_id)\n",
    "\n",
    "artist_embedding_df = pd.DataFrame(item_embeddings,\n",
    "                                   index=artist_df.artist_name)\n",
    "\n",
    "artist_embedding_df[num_factor] = item_bias[:,0]\n",
    "artist_embedding_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들면 가수 리한나의 임베딩 결과는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26963  0.04856  0.33164  0.24663 -0.27721  0.20203 -0.0955   0.35793\n",
      " -0.25274  0.34072  0.31541 -0.18788 -0.3396  -0.41544  0.11444  0.3265\n",
      "  0.2011  -0.15    -0.38465  0.55826 -0.13538 -0.37079 -0.30983 -0.03116\n",
      "  0.46811  0.14085  0.32425  0.08879 -0.20715  0.0675  -0.09464  0.48116\n",
      "  0.14322]\n"
     ]
    }
   ],
   "source": [
    "print(artist_embedding_df.loc[\"rihanna\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  즐겨듣는 아티스트와 유사한 아티스트 추천하기\n",
    "\n",
    "내적 연산(dot product)를 통해 두 벡터의 유사도를 계산할 수 있다고 배웠습니다. 각 아티스트의 임베딩을 다른 아티스트의 임베딩과 내적 연산하여 아티스트 사이의 유사도를 구하면, 각 아티스트와 가장 높은 유사도를 가진 아티스트를 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 제이슨 므라즈와 유사한 아티스트 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "mozella                   2.814972\n",
       "josh kelley               2.806064\n",
       "matt wertz                2.772019\n",
       "jason reeves              2.766373\n",
       "teddy geiger              2.703305\n",
       "justin nozuka             2.701589\n",
       "jeremy kay                2.651573\n",
       "jamie scott & the town    2.649342\n",
       "eric hutchinson           2.634584\n",
       "gavin degraw              2.634161\n",
       "dtype: float32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_embedding = artist_embedding_df.loc['jason mraz']\n",
    "\n",
    "(\n",
    "    artist_embedding_df\n",
    "    .dot(target_embedding)\n",
    "    .sort_values(ascending=False)\n",
    "    .iloc[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 브리트니 스피어스와 유사한 아티스트 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "girlicious          3.007082\n",
       "the saturdays       2.964588\n",
       "billie              2.933447\n",
       "paris hilton        2.902036\n",
       "victoria beckham    2.900184\n",
       "nadia oh            2.896300\n",
       "kate alexa          2.894922\n",
       "agnes carlsson      2.880454\n",
       "basim               2.862728\n",
       "alesha dixon        2.859251\n",
       "dtype: float32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_embedding = artist_embedding_df.loc['britney spears']\n",
    "\n",
    "(\n",
    "    artist_embedding_df\n",
    "    .dot(target_embedding)\n",
    "    .sort_values(ascending=False)\n",
    "    .iloc[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에미넴과 유사한 아티스트 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "lil jon                      2.426599\n",
       "eminem & 50 cent             2.420105\n",
       "afroman                      2.416948\n",
       "d12                          2.393669\n",
       "eminem                       2.388535\n",
       "silkk the shocker            2.377112\n",
       "diaz                         2.366818\n",
       "herreløse                    2.342267\n",
       "50 cent                      2.319996\n",
       "jamie kennedy & stu stone    2.305045\n",
       "dtype: float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_embedding = artist_embedding_df.loc['eminem']\n",
    "\n",
    "(\n",
    "    artist_embedding_df\n",
    "    .dot(target_embedding)\n",
    "    .sort_values(ascending=False)\n",
    "    .iloc[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자신의 취향과 비슷한 특성을 가진 아티스트 추천하기\n",
    "\n",
    "앞서 한 아티스트의 임베딩 벡터와 전체 아티스트의 임베딩 행렬을 이용해 아티스트 사이의 유사도를 구하여 유저가 즐겨듣는 아티스트와 유사한 아티스트를 추천해보았습니다. 이번에는 유저 임베딩 벡터와 전체 아티스트의 임베딩 행렬을 이용해 유저와 비슷한 아티스트를 찾아 추천해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별 이미 들은 아티스트 리스트 구성하기\n",
    "artistset_per_user = (\n",
    "    play_df\n",
    "    .groupby('user_id')\n",
    "    ['artist_id']\n",
    "    .apply(frozenset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**메탈, 락과 같은 음악을 많은 들은 사람**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_id2name = dict(\n",
    "    zip(artist_df.artist_id.values, artist_df.artist_name.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angelo badalamenti', 'red hot chili peppers', 'marilyn manson', 'led zeppelin', 'eric clapton', 'metallica', 'iron maiden', 'u2', 't.love', 'slipknot', 'queens of the stone age', \"guns n' roses\", 'iced earth', 'avril lavigne', 'guano apes', 'the offspring', 'alice in chains', 'in flames', 'pantera', 'john williams', 'daniel licht', 'high and mighty color', 'karmacoma', 'down', 'missile girl scoot', 'akira yamaoka', 'the kilimanjaro darkjazz ensemble', 'mondo generator', 'raging speedhorn', 'graeme revell', 'spiritual beggars', 'as i lay dying', 'frida snell', 'fatboy slim', 'pearl jam', 'isis', 'suicidal tendencies', 'black sabbath', 'stone sour', 'the smashing pumpkins', 'sigur rós', 'godsmack', 'pink', 'no doubt', 'nine inch nails']\n"
     ]
    }
   ],
   "source": [
    "target_id = 300\n",
    "target_user = user_embedding_df.loc[target_id]\n",
    "target_user.loc[32] = 1\n",
    "print([artist_id2name[f] for f in artistset_per_user[target_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target_user와 유사도가 높은 아티스트를 보면 아래와 같이 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "downface                 3.659676\n",
       "deponeye                 3.342204\n",
       "cad                      3.201091\n",
       "vokee                    3.060442\n",
       "jonathan davis           3.041707\n",
       "gothacoustic ensemble    3.034197\n",
       "jay gordon               3.024186\n",
       "hurt                     3.017704\n",
       "convergence              3.016421\n",
       "godsmack                 3.004003\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    artist_embedding_df\n",
    "    .dot(target_user) # target_user와 유사도 계산하기\n",
    "    .sort_values(ascending=False)\n",
    "    [:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**힙합을 많이 들은 사람**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the stone roses', 'snow patrol', 'red hot chili peppers', 'nickelback', 'scouting for girls', 'blur', 'michael jackson', 'michael bublé', 'amy winehouse', 'u2', 'the fratellis', 'bob marley', 'busted', 'jay-z', 'prince', 'kanye west', 'jordin sparks', 'foo fighters', '2pac', 'arctic monkeys', '50 cent', 'coldplay', 'lil wayne', 'the jackson 5', 'shaggy', 'queen', 'the game', 'feeder', 'the streets', 'radiohead', 'jay-z and linkin park', 'rihanna', 'linkin park', 'nina simone', 'blink-182', 'basshunter', 'r. kelly', 'oasis', 'the view', 'usher', 'the verve', 'akon', 'rod stewart', 'stereophonics', 'hard-fi']\n"
     ]
    }
   ],
   "source": [
    "target_id = 1200\n",
    "target_user = user_embedding_df.loc[target_id]\n",
    "target_user.loc[32] = 1\n",
    "print([artist_id2name[f] for f in artistset_per_user[target_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "danny bond                              3.428761\n",
       "chris lee                               3.386015\n",
       "4th25                                   3.378803\n",
       "rush hour                               3.347842\n",
       "multicyde                               3.251757\n",
       "eamon                                   3.250701\n",
       "dj greg j                               3.236316\n",
       "jokeren                                 3.217016\n",
       "justin timberlake & timbaland           3.212935\n",
       "donavon frankenreiter & jack johnson    3.169665\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    artist_embedding_df\n",
    "    .dot(target_user) # target_user와 유사도 계산하기\n",
    "    .sort_values(ascending=False)\n",
    "    [:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**댄스 음악을 좋아하는 사람**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gackt', 'christina aguilera', 'beyoncé', 'michael jackson', '安室奈美恵', '12012', '이효리', '新垣結衣', '久石譲', '鄭秀文', 'olivia ong', 'donawhale', '王力宏', 'enrique iglesias', 'alan', 'late night alumni', 'vanessa paradis', 'big bang', 'uverworld', 'abingdon boys school', 'britney spears', 'jennifer lopez', 'timbaland', 'ciara', 'bon jovi', 'avril lavigne', '中島美嘉', '浜崎あゆみ', 'm-flo', 'evanescence', '宇多田ヒカル', 'olivia', '倖田來未', 'spice girls', 'ashlee simpson', 'mariah carey', 'rihanna', 'linkin park', 'nelly furtado', 'madonna', 'enya', 'the pussycat dolls', 'kelly clarkson', 'michelle branch', 'frank sinatra', 'bee gees', 'justin timberlake', 'lady gaga', 'mink', 'boa', 'ガゼット', 'disney']\n"
     ]
    }
   ],
   "source": [
    "target_id = 209\n",
    "target_user = user_embedding_df.loc[target_id]\n",
    "target_user.loc[32] = 1\n",
    "print([artist_id2name[f] for f in artistset_per_user[target_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 202 ms, sys: 71 ms, total: 273 ms\n",
      "Wall time: 112 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "sweetbox            4.096132\n",
       "kate alexa          4.092253\n",
       "koh  mr. saxman     4.075683\n",
       "g-dragon            4.044978\n",
       "kristine sa         4.032140\n",
       "field of view       4.006198\n",
       "tashannie           4.004965\n",
       "โต๋-ศักดิ์สิทธิ์    3.957015\n",
       "mateo               3.932843\n",
       "阿桑                  3.928469\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    artist_embedding_df\n",
    "    .dot(target_user) # target_user와 유사도 계산하기\n",
    "    .sort_values(ascending=False)\n",
    "    [:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization Serving\n",
    "\n",
    "위와 같이 우리는 고객에 대한 Embedding Vector, 아티스트에 대한 Embedding Vector을 구했습니다. 그리고 이러한 Embedding Vector을 통해 어떻게 고객에게 적절히 추천할 수 있는지에 대해서도 알아봤습니다. 그럼 이를 통해 서비스를 한다면, 어떻게 해야 할까요?\n",
    "\n",
    "![Imgur](https://i.imgur.com/aTkb7jB.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 주기적으로 배치 서버를 통해 BPR 알고리즘을 통해 고객과 제품에 대한 Embedding Vector을 학습시켜 주면 됩니다. <br>\n",
    "그럼 고객에게 추천을 할 때는 어떻게 해야할까요? 위와 같이 Pandas를 이용해, 유사도를 계산할 수 있지만 이럴 경우 우리는 대량의 요청이 들어왔을 때 빠르게 응답하기 어려울 수 있습니다. 고객의 경험을 위해서는 최소 100ms안에 요청을 처리할 수 있어야 합니다. 하지만 Pandas로는 어렵습니다. 이를 위해 Spotify에서는 자체 추천 서비스를 위한 도구인 Annoy를 오픈소스로 공개하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify 팀의 서빙 도구, Annoy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoy는 위와 같이 전체 제품 중 고객에게 맞는 제품을 추천하기 위해, Dot 연산을 수행하여 제일 가까운 10개를 찾는 연산을 보다 빠르게 만들기 위한 라이브러리입니다. Annoy는 위와 같이 모든 제품과 Dot 연산을 수행하는 것이 아닌, 가장 가까울 것으로 예상되는 제품만을 추려 Dot 연산을 수행하는 방식으로 설계되어 있습니다. 즉 가까운 제품끼리 미리 클러스터링을 진행 후, 해당 제품끼리에서만 Dot 연산을 수행하여 최소의 연산으로 우리가 필요한 정보를 추출할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 준비하기\n",
    "\n",
    "우선 우리는 학습한 제품의 Embedding Vector을 Annoy에 저장해야 합니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = AnnoyIndex(33, \"dot\") # Dot 유사도를 이용하기\n",
    "\n",
    "for idx, value in enumerate(artist_embedding_df.values):\n",
    "    tree.add_item(idx, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 몇 개의 Tree를 통해 군집화를 할 것인지 설정합니다. <br> 이 때 Tree가 많을수록 좀 더 정확하게 군집화할 수 있고, 적을수록 좀 더 빠르게 연산을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.build(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Annoy를 통해 유사도 검색하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**메탈, 락과 같은 음악을 많은 들은 사람**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angelo badalamenti', 'red hot chili peppers', 'marilyn manson', 'led zeppelin', 'eric clapton', 'metallica', 'iron maiden', 'u2', 't.love', 'slipknot', 'queens of the stone age', \"guns n' roses\", 'iced earth', 'avril lavigne', 'guano apes', 'the offspring', 'alice in chains', 'in flames', 'pantera', 'john williams', 'daniel licht', 'high and mighty color', 'karmacoma', 'down', 'missile girl scoot', 'akira yamaoka', 'the kilimanjaro darkjazz ensemble', 'mondo generator', 'raging speedhorn', 'graeme revell', 'spiritual beggars', 'as i lay dying', 'frida snell', 'fatboy slim', 'pearl jam', 'isis', 'suicidal tendencies', 'black sabbath', 'stone sour', 'the smashing pumpkins', 'sigur rós', 'godsmack', 'pink', 'no doubt', 'nine inch nails']\n"
     ]
    }
   ],
   "source": [
    "target_id = 300\n",
    "target_user = user_embedding_df.loc[target_id]\n",
    "target_user.loc[num_factor] = 1\n",
    "print([artist_id2name[f] for f in artistset_per_user[target_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoy를 통해 검색하려면 아래와 같이 작성하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 681 µs, sys: 103 µs, total: 784 µs\n",
      "Wall time: 543 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "artist_indices = tree.get_nns_by_vector(target_user, 10)\n",
    "artist_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoy를 통해 검색하게 되면 훨씬 더 빠른 속도 내에 처리할 수 있습니다. 현재 컴퓨터 성능으로는 대략 200배 정도 빨라집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 인덱스를 아티스트 이름으로 바꾸면 아래와 같게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['melody.', 'f4', 'twins', 'joanna wang', 'lmnt', '范逸臣', '林俊傑',\n",
       "       'tanya chua', 'cẩm ly', '許茹芸'],\n",
       "      dtype='object', name='artist_name')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_embedding_df.index[artist_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**힙합을 많이 들은 사람**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the stone roses', 'snow patrol', 'red hot chili peppers', 'nickelback', 'scouting for girls', 'blur', 'michael jackson', 'michael bublé', 'amy winehouse', 'u2', 'the fratellis', 'bob marley', 'busted', 'jay-z', 'prince', 'kanye west', 'jordin sparks', 'foo fighters', '2pac', 'arctic monkeys', '50 cent', 'coldplay', 'lil wayne', 'the jackson 5', 'shaggy', 'queen', 'the game', 'feeder', 'the streets', 'radiohead', 'jay-z and linkin park', 'rihanna', 'linkin park', 'nina simone', 'blink-182', 'basshunter', 'r. kelly', 'oasis', 'the view', 'usher', 'the verve', 'akon', 'rod stewart', 'stereophonics', 'hard-fi']\n"
     ]
    }
   ],
   "source": [
    "target_id = 1200\n",
    "target_user = user_embedding_df.loc[target_id]\n",
    "target_user.loc[num_factor] = 1\n",
    "print([artist_id2name[f] for f in artistset_per_user[target_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoy를 통해 검색하면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_indices = tree.get_nns_by_vector(target_user, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 인덱스를 아티스트 이름으로 바꾸면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chris lee', '4th25', 'dj greg j', 'pato', 'titofelix', 'karmacy',\n",
       "       'scouting for girls', 'alain clark', 'jet', 'sir speedy'],\n",
       "      dtype='object', name='artist_name')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_embedding_df.index[artist_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**댄스 음악을 좋아하는 사람**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gackt', 'christina aguilera', 'beyoncé', 'michael jackson', '安室奈美恵', '12012', '이효리', '新垣結衣', '久石譲', '鄭秀文', 'olivia ong', 'donawhale', '王力宏', 'enrique iglesias', 'alan', 'late night alumni', 'vanessa paradis', 'big bang', 'uverworld', 'abingdon boys school', 'britney spears', 'jennifer lopez', 'timbaland', 'ciara', 'bon jovi', 'avril lavigne', '中島美嘉', '浜崎あゆみ', 'm-flo', 'evanescence', '宇多田ヒカル', 'olivia', '倖田來未', 'spice girls', 'ashlee simpson', 'mariah carey', 'rihanna', 'linkin park', 'nelly furtado', 'madonna', 'enya', 'the pussycat dolls', 'kelly clarkson', 'michelle branch', 'frank sinatra', 'bee gees', 'justin timberlake', 'lady gaga', 'mink', 'boa', 'ガゼット', 'disney']\n"
     ]
    }
   ],
   "source": [
    "target_id = 209\n",
    "target_user = user_embedding_df.loc[target_id]\n",
    "target_user.loc[num_factor] = 1\n",
    "print([artist_id2name[f] for f in artistset_per_user[target_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoy를 통해 검색하면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_indices = tree.get_nns_by_vector(target_user, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 인덱스를 아티스트 이름으로 바꾸면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['melody.', 'f4', 'twins', 'joanna wang', 'lmnt', '范逸臣', '林俊傑',\n",
       "       'tanya chua', 'cẩm ly', '許茹芸'],\n",
       "      dtype='object', name='artist_name')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_embedding_df.index[artist_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Annoy와 유사한 다양한 라이브러리들\n",
    "\n",
    "Annoy와 같이 Embedding Vector의 유사도를 빠르게 계산해주는 라이브러리들이 많이 존재합니다. 이 중 Annoy는 성능은 준수한 수준에, 매우 간단하게 이용할 수 있어 많이 사용됩니다.\n",
    "\n",
    "<img src=\"https://github.com/erikbern/ann-benchmarks/raw/master/results/glove-100-angular.png\" width=\"500\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
