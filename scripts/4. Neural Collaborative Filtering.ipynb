{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "BPR을 이용한 Matrix Factorization은 효과적이나, 고객의 취향 행렬과 제품의 특성 행렬 간의 선형 관계만을 파악할 수 있다는 점에서 한계가 있습니다. 좀 더 복잡한 고객의 취향 <-> 특성 행렬 간 관계를 파악하기 위해 딥러닝을 Matrix Factorization에 적용하는 연구가 진행되었습니다. 이 중 대표적인 모델이 바로 아래 소개된 `Neural Collaborative Filtering`입니다.\n",
    "\n",
    "* Code Reference : [Paper's Implementation](https://github.com/hexiangnan/neural_collaborative_filtering/blob/master/MLP.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 모듈 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()\n",
    "np.set_printoptions(5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "ROOT_URL = \"https://craftsangjae.s3.ap-northeast-2.amazonaws.com/data/\"\n",
    "\n",
    "# 데이터 가져오기\n",
    "play_path = get_file(\"lastfm_play.csv\",\n",
    "                     ROOT_URL+\"lastfm_play.csv\")\n",
    "artist_path = get_file(\"lastfm_artist.csv\",\n",
    "                       ROOT_URL+\"lastfm_artist.csv\")\n",
    "user_path = get_file(\"lastfm_user.csv\",\n",
    "                     ROOT_URL+\"lastfm_user.csv\")\n",
    "\n",
    "play_df = pd.read_csv(play_path)\n",
    "artist_df = pd.read_csv(artist_path)\n",
    "user_df = pd.read_csv(user_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Neural Collaborative Filtering 구현하기\n",
    "\n",
    "<img src=\"https://i.imgur.com/B0lLZEg.png\" width=\"400\">\n",
    "\n",
    "Neural Collaborative Filtering은 이 구조도로 모델링을 설명할 수 있습니다.  유저의 임베딩 값과 아이템의 임베딩 값을 딥러닝의 Input으로 들어가게 됩니다. 그리고 4층을 걸쳐 출력값으로 고객이 해당 아이템을 선호할 확률이 나오게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 구성하기\n",
    "\n",
    "우선 user와 item이 쌍으로 Input으로 들어가게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "user_id = Input(shape=(), name='user')\n",
    "item_id = Input(shape=(), name='item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 레이어 구성하기\n",
    "\n",
    "임베딩의 크기는 논문에서 알려져 있듯, 값이 커질수록 그 성능이 올라갑니다. 여기에서는 32로 두도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "num_user = play_df.user_id.max() + 1\n",
    "num_item = play_df.artist_id.max() + 1\n",
    "num_factor = 32\n",
    "\n",
    "user_embedding = Embedding(num_user, num_factor)(user_id)\n",
    "item_embedding = Embedding(num_item, num_factor)(item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCF Layers 구성하기\n",
    "\n",
    "`Dense` 레이어가 순서대로 적층되어 있는 단순한 구조를 띕니다. 논문에서 서술되어 있는 방식으로, 3층 구조로 unit수가 ( 32 $\\rightarrow$ 16 $\\rightarrow$ 8 )로 줄어드는 순서로 작성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "concat_embedding = Concatenate()(\n",
    "    [user_embedding, item_embedding])\n",
    "\n",
    "hidden1 = Dense(32, activation='relu')(concat_embedding)\n",
    "hidden2 = Dense(16, activation='relu')(hidden1)\n",
    "hidden3 = Dense(8, activation='relu')(hidden2)\n",
    "probs = Dense(1, activation='sigmoid')(hidden3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Model 구성하기\n",
    "\n",
    "입력값은 `user_id`와 `item_id`가 Pair로 들어가게 되고, 출력값은 `user_id`가 `item_id`를 선호할 확률이 계산됩니다.  `user_id`가 `item_id`를 구매하거나 산 적이 있으면 1이 나와야 하고, `user_id`가 `item_id`를 구매하거나 산 적이 없다면 0이 나아야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model([user_id, item_id],  probs, name='NCF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문에서 학습하기 위해 `Adam` 옵티마이저를 이용하였고, 손실함수로서는 `BinaryCrossentropy`를 이용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "model.compile(Adam(1e-3), \n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습하기\n",
    "\n",
    "Bayesian Personalized Ranking과 마찬가지로, 데이터는 오로지 고객이 평가한 영화에 대한 정보만 존재합니다. 모델을 학습하기 위해서, 고객이 평가하지 않은 영화에 대한 정보 또한 필요합니다. 보지 않은 영화 모두를 가져오게 되면 지나치게 많은 데이터가 생기므로 그중에서 일부분만 샘플링을 통해 추출하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 파이프라인 : Negative Sampling 수행하기\n",
    "\n",
    "NCF 모델은 user, item의 쌍으로 추론합니다. 해당 User가 해당 Item을 선호할 확률을 추론하기 때문에, 실제로 클릭 혹은 구매한 적이 있으면 학습 데이터의 라벨로는 1을 주고 클릭한적이 없다면 학습 데이터의 라벨로는 0을 줍니다. 유저가 클릭하지 않은 아이템을 Negative Sample이라 하고, 우리는 Negative Sample을 만들어주어야 합니다. <br>\n",
    "\n",
    "NCF 모델에서 Positive Sample 대비 Negative Sampling의 비율을 보통 3.~6. 사이로 두는 것을 권고합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습시키기\n",
    "\n",
    "epoch 10번에 걸쳐, 모델을 학습시키도록 하겠습니다. 매 Epoch마다 새로운 학습 데이터를 생성하도록 하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10\n",
    "batch_size = 1024\n",
    "for i in range(epoch):\n",
    "    print(f\"{i+1}th epoch :\")\n",
    "    dataset = \n",
    "    model.fit(dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기\n",
    "\n",
    "Bayesian Personalized Ranking 대비 성능을 비교하기 위해 Hit Ratio를 산출해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit = 0.\n",
    "for i, row in tqdm(hit_ratio_df.iterrows()):\n",
    "    user = np.array([row.user_id])\n",
    "    seens = np.array([row.item_id])\n",
    "    pos_scores = model.predict([user,seens])\n",
    "    pos_scores = pos_scores[0,0]\n",
    "    \n",
    "    not_seens = np.array(row.not_seen_list)\n",
    "    users = np.array([row.user_id]*len(not_seens))   \n",
    "    neg_scores = model.predict([users,not_seens])\n",
    "    \n",
    "    if pos_scores > np.sort(neg_scores.flatten())[-10]:\n",
    "        hit += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_ratio = hit / len(hit_ratio_df)        \n",
    "print(f\"hit ratio : {hit_ratio:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
