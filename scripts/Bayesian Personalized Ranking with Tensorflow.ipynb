{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()\n",
    "np.set_printoptions(5,)\n",
    "assert int(tf.__version__[0]) == 2, \"tensorflow 2.0 should be installed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "ROOT_URL = \"https://craftsangjae.s3.ap-northeast-2.amazonaws.com/data/\"\n",
    "\n",
    "play_path = get_file(\"lastfm_play.csv\",\n",
    "                     ROOT_URL+\"lastfm_play.csv\")\n",
    "artist_path = get_file(\"lastfm_artist.csv\",\n",
    "                       ROOT_URL+\"lastfm_artist.csv\")\n",
    "user_path = get_file(\"lastfm_user.csv\",\n",
    "                     ROOT_URL+\"lastfm_user.csv\")\n",
    "\n",
    "play_df = pd.read_csv(play_path)\n",
    "artist_df = pd.read_csv(artist_path)\n",
    "user_df = pd.read_csv(user_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Personalized Ranking\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dot, Concatenate\n",
    "from tensorflow.keras.layers import Embedding, Subtract\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def bayesian_personalized_ranking(num_user, num_item, num_factor, l2_reg=1e-2):\n",
    "    user_id = Input(shape=(), name='user')\n",
    "    pos_item_id = Input(shape=(), name='pos_item')\n",
    "    neg_item_id = Input(shape=(), name='neg_item')\n",
    "    \n",
    "    # initializer For Embedding Layer\n",
    "    initializer = RandomUniform(minval=-1/num_factor,\n",
    "                                maxval= 1/num_factor)\n",
    "    \n",
    "    user_embedding_layer = Embedding(num_user, num_factor, \n",
    "                                     embeddings_initializer=initializer,\n",
    "                                     name='user_embedding')\n",
    "    item_embedding_layer = Embedding(num_item, num_factor, \n",
    "                                     embeddings_initializer=initializer,\n",
    "                                     name='item_embedding')\n",
    "    item_bias_layer = Embedding(num_item, 1, \n",
    "                                embeddings_initializer='zeros',\n",
    "                                name='item_bias')\n",
    "    \n",
    "    user_embedding = user_embedding_layer(user_id)\n",
    "    \n",
    "    pos_item_embedding = item_embedding_layer(pos_item_id)\n",
    "    neg_item_embedding = item_embedding_layer(neg_item_id)\n",
    "    \n",
    "    pos_item_bias = item_bias_layer(pos_item_id)\n",
    "    neg_item_bias = item_bias_layer(neg_item_id)\n",
    "    \n",
    "    # Calculation the Score Difference between positive and negative\n",
    "    pos_score = (\n",
    "        Dot(axes=(1,1))([user_embedding, pos_item_embedding]) + pos_item_bias)\n",
    "    neg_score = (\n",
    "        Dot(axes=(1,1))([user_embedding, neg_item_embedding]) + neg_item_bias)\n",
    "\n",
    "    score = Subtract()([pos_score, neg_score])\n",
    "    \n",
    "    model = Model([user_id, pos_item_id, neg_item_id], score)\n",
    "        \n",
    "    # Add L2 Regularization Term\n",
    "    l2_pos_item = l2(l2_reg)(pos_item_embedding)\n",
    "    l2_neg_item = l2(l2_reg)(neg_item_embedding)\n",
    "    l2_user = l2(l2_reg)(user_embedding)\n",
    "    l2_loss = l2_pos_item+l2_neg_item+l2_user\n",
    "    model.add_loss(l2_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = play_df.user_id.max() + 1\n",
    "num_item = play_df.artist_id.max() + 1\n",
    "num_factor = 32\n",
    "\n",
    "model = bayesian_personalized_ranking(num_user, num_item, 32, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "model.compile(optimizer=Adagrad(1e-1),\n",
    "              loss=BinaryCrossentropy(from_logits=True, reduction='sum'), \n",
    "              metrics=[BinaryAccuracy(threshold=0.)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Data Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_dataset(df, batch_size=4096):\n",
    "    bootstrap = df.sample(frac=1., replace=True)\n",
    "    user_ids = bootstrap.user_id.values\n",
    "    pos_item_ids = bootstrap.artist_id.values\n",
    "    neg_item_ids = df.artist_id.sample(frac=1., replace=True).values\n",
    "\n",
    "    X = {\n",
    "        \"user\": user_ids,\n",
    "        \"pos_item\": pos_item_ids,\n",
    "        \"neg_item\": neg_item_ids\n",
    "    }\n",
    "    dummy_y = np.ones((len(bootstrap), 1))\n",
    "    \n",
    "    dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((X,dummy_y))\n",
    "        .batch(batch_size))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 50\n",
    "batch_size = 4096\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    print(f\"{i+1}th epoch\")\n",
    "    dataset = bootstrap_dataset(play_df, batch_size)\n",
    "    model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend Items using Model\n",
    "\n",
    "* case 1. Find Similar Artists\n",
    "* case 2. Find artists to recommend to users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get artist & User Embedding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Embedding weights\n",
    "user_embeddings = model.get_layer('user_embedding').get_weights()[0]\n",
    "item_embeddings = model.get_layer('item_embedding').get_weights()[0]\n",
    "item_bias = model.get_layer('item_bias').get_weights()[0]\n",
    "\n",
    "# Convert numpy array to Dataframe\n",
    "user_embedding_df = pd.DataFrame(user_embeddings, \n",
    "                                 index=user_df.user_id)\n",
    "user_embedding_df[num_factor] = 1.\n",
    "\n",
    "artist_embedding_df = pd.DataFrame(item_embeddings,\n",
    "                                   index=artist_df.artist_name)\n",
    "artist_embedding_df[num_factor] = item_bias[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 1. Find Similar Artists\n",
    "\n",
    "> Which artist is similar to `jason mraz`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "jason mraz        2.948219\n",
       "jason reeves      2.874918\n",
       "justin nozuka     2.836041\n",
       "matt white        2.792048\n",
       "gavin degraw      2.775528\n",
       "matt wertz        2.767827\n",
       "john mayer        2.709603\n",
       "james morrison    2.701028\n",
       "colbie caillat    2.696645\n",
       "teddy geiger      2.693708\n",
       "dtype: float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommend 10 artists\n",
    "target_embedding = artist_embedding_df.loc['jason mraz']\n",
    "\n",
    "(\n",
    "    artist_embedding_df\n",
    "    .dot(target_embedding)\n",
    "    .sort_values(ascending=False)\n",
    "    .iloc[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 2. Find artists to recommend to users\n",
    "\n",
    "> Find artist for dancing songs lovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of artists that the user has heard\n",
      "['安室奈美恵' '浜崎あゆみ' 'britney spears' '12012' '中島美嘉' '倖田來未' '이효리' '宇多田ヒカル'\n",
      " 'madonna' 'michael jackson' '新垣結衣' 'rihanna' 'mariah carey' 'evanescence'\n",
      " 'linkin park' '久石譲' 'olivia' 'christina aguilera' '鄭秀文' 'boa' 'disney'\n",
      " 'olivia ong' 'donawhale' '王力宏' 'bee gees' 'gackt' 'enya'\n",
      " 'the pussycat dolls' 'ashlee simpson' 'm-flo' 'enrique iglesias' 'alan'\n",
      " 'ガゼット' 'late night alumni' 'michelle branch' 'nelly furtado'\n",
      " 'vanessa paradis' 'big bang' 'spice girls' 'beyoncé' 'uverworld'\n",
      " 'frank sinatra' 'avril lavigne' 'mink' 'bon jovi' 'abingdon boys school'\n",
      " 'jennifer lopez' 'kelly clarkson' 'lady gaga' 'timbaland'\n",
      " 'justin timberlake' 'ciara']\n"
     ]
    }
   ],
   "source": [
    "target_user_id = 209\n",
    "listened_artists = play_df[play_df.user_id==target_user_id].artist_id\n",
    "\n",
    "print(\"List of artists that the user has heard\")\n",
    "print(artist_df.loc[listened_artists.values,\"artist_name\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name\n",
       "蔡依林             4.555263\n",
       "sweetbox        4.500760\n",
       "boa             4.447616\n",
       "倖田來未            4.417671\n",
       "권보아             4.410030\n",
       "utada           4.397315\n",
       "twins           4.368110\n",
       "宇多田ヒカル          4.359187\n",
       "wonder girls    4.352513\n",
       "dream           4.342292\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_user = user_embedding_df.loc[target_user_id]\n",
    "\n",
    "(\n",
    "    artist_embedding_df\n",
    "    .dot(target_user)\n",
    "    .sort_values(ascending=False)\n",
    "    [:10]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
